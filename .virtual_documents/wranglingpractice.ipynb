import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# importing necessary packages


filepath = '/Users/vaibhavjha/wrangling/data/sharks.csv'
sharks = pd.read_csv(filepath, low_memory = False)

# reading in the file


sharks.head()
#sharks.shape

# getting feel for size, rows, columns


sharks.loc[1:10, ('Location', 'Name', 'Activity')]

# searching with loc, uses locator class

sharks.iloc[9:19, 1:4]

# searching with iloc[], uses integer locator class method


sharks.loc[:,'Fatal (Y/N)']
sharks = sharks.rename(columns = {'Fatal (Y/N)':'Fatal'})
sharks.loc[:,'Fatal']


sharks.dtypes
sharks['Type'].unique()


url = 'http://www.vcsc.virginia.gov/pretrialdataproject/October%202017%20Cohort_Virginia%20Pretrial%20Data%20Project_Deidentified%20FINAL%20Update_10272021.csv'
df = pd.read_csv(url,low_memory=False)
df.columns # Read in Virginia trial data


# Missing data

var = 'Defendant_Age'
print(df[var].unique())
# In social science, every interesting problem is fundamentally a missing data issue.
# In Pandas, there are two options for representing missing values
# - the default is to treat it as an np.nan from the NumPy package ('not a number') and its type is a float
# - Pandas also treats a missing value as a None: an empty/null object without a type or value


df['Defendant_Age'].hist()


# Sharks missing data

sharks.loc[:,['Year', 'Age', 'Type', 'Activity']]
sharks['Year'].tolist()
locmissing = sharks['Location'].isna().sum()
print(locmissing)


# Cleaning Age in sharks
sharks['Age'].value_counts()
sharks['Age'].isnull() # Shows which values in Age are 






import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


law = pd.read_excel('/Users/vaibhavjha/ds3001/Python-data-wrangling-examples-Practical-Exercises-with-Solutions/data/ex1_RAW.xlsx')
law.head(15)









role_list = []
for index, row in law.iterrows():
    role = row['position'].replace(row['name'], '').strip()
    role_list.append(role)

law['role'] = role_list

law.head(15)





url = 'https://sis.ou.edu/ted/home/byOther?stat_code=TX&sbgi_code=UTX031&trns_subj_code=&trns_subj_crse='

credit = pd.read_html(url)
credit[0]

# Regenerating the columns
credit[0]['from_school'] = 'Woodcrest College'
credit[0]['from_course_department'] = credit[0]['Transfer Subject']
credit[0]['from_course_code'] = credit[0]['Transfer Course']
credit[0]['from_course_name'] =credit[0]['Transfer Title']
credit[0]['from_course_credit_hours'] = credit[0]['Transfer Hours']
credit[0]['to_course_department'] = credit[0]['OU Subject']
credit[0]['to_course_code'] = credit[0]['OU Course']
credit[0]['to_course_name'] = credit[0]["OU Title"]
credit[0]['to_course_credit_hours'] = credit[0]['OU Credits']
credit[0]['to_school'] = 'University of Oklahoma' # renamed columns for liking

credit[0]

final_credit = credit[0][['from_school', 'from_course_department', 'from_course_code', 
                          'from_course_name', 'from_course_credit_hours', 'to_course_department', 'to_course_code',
                          'to_course_name', 'to_course_credit_hours', 'to_school']] # made final df with relevant columns
final_credit

dict_1 = final_credit.to_dict(orient = 'records')
dict_1 # converted dataframe to dictionary

university_json = json.dumps(dict_1)
print(university_json) # converted dictionary to json





languages = pd.read_excel('/Users/vaibhavjha/ds3001/Python-data-wrangling-examples-Practical-Exercises-with-Solutions/data/ex3_RAW.xlsx')
languages

def speak(aStr):
    if 'Speaks' in aStr:
        return aStr.split('Speaks')[1].split('\n')[0].strip()
    else:
        return '' # defined a function speak with one parameter to identify languages section using keyword 'Speaks'

languages['Speak'] = languages['Language'].apply(lambda x:speak(x)) # applied the function speak through the languages df
languages

languages['Speak'] = languages['Speak'].apply(lambda x:x.replace(' and ', ', ')) # removed 'and' by replacing it with ','
languages_2 = languages.assign(Speak = languages.Speak.str.split(",")) # Converted the Speak column to list
languages_3 = languages_2['Speak'].apply(pd.Series) # Separated the list column into individual columns
languages_4 = pd.concat([languages_2, languages_3], axis = 1) # Concatenated the whole df with the individual columns
languages_4.head(25)

languages_4[4].value_counts() # in the fourth column, Polish appeared once as did Russian
        



